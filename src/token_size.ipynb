{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same code as that of train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = '../data/dataset/IN-Abs/train-data'\n",
    "test_data = '../data/dataset/IN-Abs/test-data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"t5-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train set: 7030\n",
      "Number of test set 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (6132 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# Reading the training and testing files\n",
    "train_files = {\n",
    "    \"text\": os.listdir(train_data+'/judgement'),\n",
    "    \"summary\": os.listdir(train_data+'/summary')\n",
    "}\n",
    "test_files = {\n",
    "    \"text\": os.listdir(test_data+'/judgement'),\n",
    "    \"summary\": os.listdir(test_data+'/summary')\n",
    "}\n",
    "\n",
    "print(\"Number of train set:\", len(train_files[\"text\"]))\n",
    "print(\"Number of test set\", len(test_files[\"text\"]))\n",
    "\n",
    "\n",
    "# Loading model and the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint).to(device)\n",
    "\n",
    "# Setting Dataset transformer\n",
    "class SummaryDataset(Dataset):\n",
    "    def __init__(self, dataset_files, tokenizer, max_length=None, n_samples=None, dstype=\"train\"):\n",
    "        \"\"\"\n",
    "            Dataset Class as per the pytorch library. This is the constructor class \n",
    "            In this class the dataset folder is loaded (text and the summary)\n",
    "            data_files - List of names of input files (txt file)\n",
    "        \"\"\"\n",
    "        self.texts = []\n",
    "        self.labels = []\n",
    "        self.max_length = tokenizer.model_max_length if max_length is None else max_length \n",
    "\n",
    "        base_dir = train_data if dstype == \"train\" else test_data\n",
    "\n",
    "        # Reading \n",
    "        count = 0\n",
    "        for file in dataset_files[\"text\"]:\n",
    "            # Reading and tokenizing the text file \n",
    "            with open(base_dir+'/judgement/'+file, 'r') as f:\n",
    "                l = f.readlines()\n",
    "                l = [x.strip() for x in l]\n",
    "                text = ''.join(l) # Concatinating all lines to one line\n",
    "                # Tokenizer creates the token for the document and returns the pytorch tensor with padding for parallism in GPU\n",
    "                tok = tokenizer.tokenize(text)\n",
    "                self.texts.append(len(tok)) # Appending length instead of token\n",
    "\n",
    "                # self.texts.append(tok)\n",
    "\n",
    "            # Reading and tokenizing the summary file corresponding to the text file\n",
    "            with open(base_dir+'/summary/'+file, 'r') as f:\n",
    "                l = f.readlines()\n",
    "                l = [x.strip() for x in l]\n",
    "                text = ''.join(l) # Concatinating all lines to one line\n",
    "                # Tokenizer creates the token for the document and returns the pytorch tensor with padding for parallism in GPU\n",
    "                tok = tokenizer.tokenize(text)\n",
    "                self.labels.append(len(tok))\n",
    "\n",
    "            count += 1\n",
    "            if n_samples is not None and count == n_samples:\n",
    "                break\n",
    "  \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {'input_ids':self.texts[idx][\"input_ids\"][0], \"attention_mask\": self.texts[idx][\"attention_mask\"][0], \"labels\":self.labels[idx][\"input_ids\"][0]}\n",
    "\n",
    "\n",
    "# Loading and tokenizing the dataset\n",
    "train_dataset = SummaryDataset(train_files, tokenizer, dstype=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Input Text to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum context length in dataset: 182927\n",
      "Minimum context length in dataset: 267\n",
      "Average context length in dataset: 5800.730014224751\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame({\n",
    "    \"input_ids_length\": train_dataset.texts\n",
    "})\n",
    "\n",
    "print(\"Maximum context length in dataset:\", max(train_df['input_ids_length']))\n",
    "print(\"Minimum context length in dataset:\", min(train_df['input_ids_length']))\n",
    "print(\"Average context length in dataset:\", train_df['input_ids_length'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Summary text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum context length in dataset: 38134\n",
      "Minimum context length in dataset: 0\n",
      "Average context length in dataset: 1149.129587482219\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame({\n",
    "    \"input_ids_length\": train_dataset.labels\n",
    "})\n",
    "\n",
    "print(\"Maximum context length in dataset:\", max(train_df['input_ids_length']))\n",
    "print(\"Minimum context length in dataset:\", min(train_df['input_ids_length']))\n",
    "print(\"Average context length in dataset:\", train_df['input_ids_length'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
